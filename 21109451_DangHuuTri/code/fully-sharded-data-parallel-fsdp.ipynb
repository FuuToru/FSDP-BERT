{"cells":[{"cell_type":"markdown","metadata":{},"source":["### How to use FSDP"]},{"cell_type":"markdown","metadata":{},"source":["Setup\n","\n","1.1 Install PyTorch along with Torchvision\n","\n","1.2 Import necessary packages"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-12-15T10:49:24.613736Z","iopub.status.busy":"2024-12-15T10:49:24.612896Z","iopub.status.idle":"2024-12-15T10:49:29.364539Z","shell.execute_reply":"2024-12-15T10:49:29.363666Z","shell.execute_reply.started":"2024-12-15T10:49:24.613691Z"},"trusted":true},"outputs":[],"source":["import os\n","import argparse\n","import functools\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","\n","\n","from torch.optim.lr_scheduler import StepLR\n","\n","import torch.distributed as dist\n","import torch.multiprocessing as mp\n","from torch.nn.parallel import DistributedDataParallel as DDP\n","from torch.utils.data.distributed import DistributedSampler\n","from torch.distributed.fsdp import FullyShardedDataParallel as FSDP\n","from torch.distributed.fsdp.fully_sharded_data_parallel import (\n","    CPUOffload,\n","    BackwardPrefetch,\n",")\n","from torch.distributed.fsdp.wrap import (\n","    size_based_auto_wrap_policy,\n","    enable_wrap,\n","    wrap,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["1.3 Distributed training setup. As we mentioned FSDP is a type of data parallelism which requires a distributed training environment, so here we use two helper functions to initialize the processes for distributed training and clean up."]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-12-15T10:49:35.378875Z","iopub.status.busy":"2024-12-15T10:49:35.377942Z","iopub.status.idle":"2024-12-15T10:49:35.386760Z","shell.execute_reply":"2024-12-15T10:49:35.385878Z","shell.execute_reply.started":"2024-12-15T10:49:35.378823Z"},"trusted":true},"outputs":[],"source":["def setup(rank, world_size):\n","    os.environ['MASTER_ADDR'] = 'localhost'\n","    os.environ['MASTER_PORT'] = '12355'\n","\n","    # initialize the process group\n","    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n","\n","def cleanup():\n","    dist.destroy_process_group()"]},{"cell_type":"markdown","metadata":{},"source":["2.1 Define our toy model for handwritten digit classification.\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-12-15T10:49:37.976178Z","iopub.status.busy":"2024-12-15T10:49:37.975817Z","iopub.status.idle":"2024-12-15T10:49:37.983118Z","shell.execute_reply":"2024-12-15T10:49:37.982150Z","shell.execute_reply.started":"2024-12-15T10:49:37.976148Z"},"trusted":true},"outputs":[],"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n","        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n","        self.dropout1 = nn.Dropout(0.25)\n","        self.dropout2 = nn.Dropout(0.5)\n","        self.fc1 = nn.Linear(9216, 128)\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","\n","        x = self.conv1(x)\n","        x = F.relu(x)\n","        x = self.conv2(x)\n","        x = F.relu(x)\n","        x = F.max_pool2d(x, 2)\n","        x = self.dropout1(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.dropout2(x)\n","        x = self.fc2(x)\n","        output = F.log_softmax(x, dim=1)\n","        return output"]},{"cell_type":"markdown","metadata":{},"source":["2.2 Define a train function\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-12-15T10:49:41.193508Z","iopub.status.busy":"2024-12-15T10:49:41.193191Z","iopub.status.idle":"2024-12-15T10:49:41.199592Z","shell.execute_reply":"2024-12-15T10:49:41.198695Z","shell.execute_reply.started":"2024-12-15T10:49:41.193483Z"},"trusted":true},"outputs":[],"source":["def train(args, model, rank, world_size, train_loader, optimizer, epoch, sampler=None):\n","    model.train()\n","    ddp_loss = torch.zeros(2).to(rank)\n","    if sampler:\n","        sampler.set_epoch(epoch)\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(rank), target.to(rank)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.nll_loss(output, target, reduction='sum')\n","        loss.backward()\n","        optimizer.step()\n","        ddp_loss[0] += loss.item()\n","        ddp_loss[1] += len(data)\n","\n","    dist.all_reduce(ddp_loss, op=dist.ReduceOp.SUM)\n","    if rank == 0:\n","        print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, ddp_loss[0] / ddp_loss[1]))"]},{"cell_type":"markdown","metadata":{},"source":["2.3 Define a validation function"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-12-15T10:49:43.272061Z","iopub.status.busy":"2024-12-15T10:49:43.271743Z","iopub.status.idle":"2024-12-15T10:49:43.278582Z","shell.execute_reply":"2024-12-15T10:49:43.277694Z","shell.execute_reply.started":"2024-12-15T10:49:43.272034Z"},"trusted":true},"outputs":[],"source":["def test(model, rank, world_size, test_loader):\n","    model.eval()\n","    correct = 0\n","    ddp_loss = torch.zeros(3).to(rank)\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(rank), target.to(rank)\n","            output = model(data)\n","            ddp_loss[0] += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            ddp_loss[1] += pred.eq(target.view_as(pred)).sum().item()\n","            ddp_loss[2] += len(data)\n","\n","    dist.all_reduce(ddp_loss, op=dist.ReduceOp.SUM)\n","\n","    if rank == 0:\n","        test_loss = ddp_loss[0] / ddp_loss[2]\n","        print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n","            test_loss, int(ddp_loss[1]), int(ddp_loss[2]),\n","            100. * ddp_loss[1] / ddp_loss[2]))"]},{"cell_type":"markdown","metadata":{},"source":["2.4 Define a distributed train function that wraps the model in FSDP <br>\n","Note: to save the FSDP model, we need to call the state_dict on each rank then on Rank 0 save the overall states."]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-12-15T10:50:01.123256Z","iopub.status.busy":"2024-12-15T10:50:01.122581Z","iopub.status.idle":"2024-12-15T10:50:01.132575Z","shell.execute_reply":"2024-12-15T10:50:01.131849Z","shell.execute_reply.started":"2024-12-15T10:50:01.123223Z"},"trusted":true},"outputs":[],"source":["def fsdp_main(rank, world_size, args):\n","    setup(rank, world_size)\n","\n","    transform=transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.1307,), (0.3081,))\n","    ])\n","\n","    dataset1 = datasets.MNIST('../data', train=True, download=True,\n","                        transform=transform)\n","    dataset2 = datasets.MNIST('../data', train=False,\n","                        transform=transform)\n","\n","    sampler1 = DistributedSampler(dataset1, rank=rank, num_replicas=world_size, shuffle=True)\n","    sampler2 = DistributedSampler(dataset2, rank=rank, num_replicas=world_size)\n","\n","    train_kwargs = {'batch_size': args.batch_size, 'sampler': sampler1}\n","    test_kwargs = {'batch_size': args.test_batch_size, 'sampler': sampler2}\n","    cuda_kwargs = {'num_workers': 2,\n","                    'pin_memory': True,\n","                    'shuffle': False}\n","    train_kwargs.update(cuda_kwargs)\n","    test_kwargs.update(cuda_kwargs)\n","\n","    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n","    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n","    my_auto_wrap_policy = functools.partial(\n","        size_based_auto_wrap_policy, min_num_params=100\n","    )\n","    torch.cuda.set_device(rank)\n","\n","\n","    init_start_event = torch.cuda.Event(enable_timing=True)\n","    init_end_event = torch.cuda.Event(enable_timing=True)\n","\n","    model = Net().to(rank)\n","\n","    model = FSDP(model)\n","\n","    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n","\n","    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n","    init_start_event.record()\n","    for epoch in range(1, args.epochs + 1):\n","        train(args, model, rank, world_size, train_loader, optimizer, epoch, sampler=sampler1)\n","        test(model, rank, world_size, test_loader)\n","        scheduler.step()\n","\n","    init_end_event.record()\n","\n","    if rank == 0:\n","        print(f\"CUDA event elapsed time: {init_start_event.elapsed_time(init_end_event) / 1000}sec\")\n","        print(f\"{model}\")\n","\n","    if args.save_model:\n","        # use a barrier to make sure training is done on all ranks\n","        dist.barrier()\n","        states = model.state_dict()\n","        if rank == 0:\n","            torch.save(states, \"mnist_cnn.pt\")\n","\n","    cleanup()"]},{"cell_type":"markdown","metadata":{},"source":["2.5 Finally, parse the arguments and set the main function"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-12-15T10:50:06.224354Z","iopub.status.busy":"2024-12-15T10:50:06.223073Z","iopub.status.idle":"2024-12-15T10:50:06.237350Z","shell.execute_reply":"2024-12-15T10:50:06.236247Z","shell.execute_reply.started":"2024-12-15T10:50:06.224288Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Running on 0 GPUs\n"]}],"source":["import sys\n","import argparse\n","\n","# Reset sys.argv để bỏ qua các đối số mặc định của Jupyter\n","sys.argv = ['']\n","\n","if __name__ == '__main__':\n","    # Training settings\n","    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n","    parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n","                        help='input batch size for training (default: 64)')\n","    parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n","                        help='input batch size for testing (default: 1000)')\n","    parser.add_argument('--epochs', type=int, default=10, metavar='N',\n","                        help='number of epochs to train (default: 14)')\n","    parser.add_argument('--lr', type=float, default=1.0, metavar='LR',\n","                        help='learning rate (default: 1.0)')\n","    parser.add_argument('--gamma', type=float, default=0.7, metavar='M',\n","                        help='Learning rate step gamma (default: 0.7)')\n","    parser.add_argument('--no-cuda', action='store_true', default=False,\n","                        help='disables CUDA training')\n","    parser.add_argument('--seed', type=int, default=1, metavar='S',\n","                        help='random seed (default: 1)')\n","    parser.add_argument('--save-model', action='store_true', default=False,\n","                        help='For Saving the current Model')\n","    args = parser.parse_args()\n","\n","    torch.manual_seed(args.seed)\n","\n","    WORLD_SIZE = torch.cuda.device_count()\n","    print(f\"Running on {WORLD_SIZE} GPUs\")\n","    mp.spawn(fsdp_main,\n","        args=(WORLD_SIZE, args),\n","        nprocs=WORLD_SIZE,\n","        join=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30805,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.20"}},"nbformat":4,"nbformat_minor":4}
